{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d752e8-9ce7-408f-96b3-a9748acecb26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 6: Reading Tabular Data into DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4321ca-6c64-4170-b617-d93690ac533f",
   "metadata": {},
   "source": [
    "## Aim: Learn what DataFrames are and practice using them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9ad99-28ad-49ed-8318-58e2bc3d519f",
   "metadata": {},
   "source": [
    "### Issues covered:\n",
    "- Importing the `pandas` library\n",
    "- Using `pandas` to load a simple CSV data set\n",
    "- Get information about the DataFrames we make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b64853-3332-482a-b1b0-08a686a45386",
   "metadata": {},
   "source": [
    "## 1. Let's import `pandas` and make some DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d413a-d2c3-4d3a-b8c7-bb87834e34b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import `pandas`, then create a dataframe using the `data/weather.csv` file and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507ca506-e488-4a7e-88f7-25a2aa4cfaae",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.061527Z",
     "iopub.status.busy": "2023-10-23T10:34:48.060839Z",
     "iopub.status.idle": "2023-10-23T10:34:48.455423Z",
     "shell.execute_reply": "2023-10-23T10:34:48.454526Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Time  Temp  Rainfall\n",
      "0  2014-01-01  00:00  2.34      4.45\n",
      "1  2014-01-01  12:00  6.70      8.34\n",
      "2  2014-01-02  00:00 -1.34     10.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weather_data = pd.read_csv('../data/weather.csv')\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8d403-57a6-40de-aed0-23080192918a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Create a new dataframe which indexes by `Date` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355a9346-ee50-403e-8c5c-0996a6e2be4e",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.461001Z",
     "iopub.status.busy": "2023-10-23T10:34:48.460697Z",
     "iopub.status.idle": "2023-10-23T10:34:48.469153Z",
     "shell.execute_reply": "2023-10-23T10:34:48.468437Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Time  Temp  Rainfall\n",
      "Date                             \n",
      "2014-01-01  00:00  2.34      4.45\n",
      "2014-01-01  12:00  6.70      8.34\n",
      "2014-01-02  00:00 -1.34     10.25\n"
     ]
    }
   ],
   "source": [
    "weather_data_dates = pd.read_csv('../data/weather.csv', index_col='Date')\n",
    "print(weather_data_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af1af5-eec2-4d74-90a2-e93fcacbba39",
   "metadata": {},
   "source": [
    "## 2. Let's practice using some dataframe methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f4d2e-5bc5-480b-a5e9-f37453ef597f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "What is the memory usage of the dataframe in bytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61051add-b15d-429a-a74b-292681e36bac",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.475188Z",
     "iopub.status.busy": "2023-10-23T10:34:48.474900Z",
     "iopub.status.idle": "2023-10-23T10:34:48.486913Z",
     "shell.execute_reply": "2023-10-23T10:34:48.485409Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, 2014-01-01 to 2014-01-02\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Time      3 non-null      object \n",
      " 1   Temp      3 non-null      float64\n",
      " 2   Rainfall  3 non-null      float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 96.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "weather_data_dates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85f457-b243-47b8-a996-ac7e5c5750ab",
   "metadata": {},
   "source": [
    "What command can you use to find the dataframe's column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258e77ea-532c-4b27-9682-2eb995d9952d",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.492049Z",
     "iopub.status.busy": "2023-10-23T10:34:48.491506Z",
     "iopub.status.idle": "2023-10-23T10:34:48.499863Z",
     "shell.execute_reply": "2023-10-23T10:34:48.497523Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Temp', 'Rainfall'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(weather_data_dates.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69428372-654c-467e-87a1-6b5b0e5d7d09",
   "metadata": {},
   "source": [
    "Swap the rows and columns and `print` the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c013233-5e0e-443c-a996-434e5c1d85c8",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.506161Z",
     "iopub.status.busy": "2023-10-23T10:34:48.505601Z",
     "iopub.status.idle": "2023-10-23T10:34:48.517041Z",
     "shell.execute_reply": "2023-10-23T10:34:48.515630Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     2014-01-01 2014-01-01 2014-01-02\n",
      "Time          00:00      12:00      00:00\n",
      "Temp           2.34        6.7      -1.34\n",
      "Rainfall       4.45       8.34      10.25\n"
     ]
    }
   ],
   "source": [
    "print(weather_data_dates.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200f4b4-ac33-42ad-9558-40395f921eaf",
   "metadata": {},
   "source": [
    "Find the mean and standard deviation of the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38848201-e994-4427-81fb-23e08cac9b60",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.522238Z",
     "iopub.status.busy": "2023-10-23T10:34:48.521527Z",
     "iopub.status.idle": "2023-10-23T10:34:48.538302Z",
     "shell.execute_reply": "2023-10-23T10:34:48.537588Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Temp   Rainfall\n",
      "count  3.000000   3.000000\n",
      "mean   2.566667   7.680000\n",
      "std    4.024790   2.955791\n",
      "min   -1.340000   4.450000\n",
      "25%    0.500000   6.395000\n",
      "50%    2.340000   8.340000\n",
      "75%    4.520000   9.295000\n",
      "max    6.700000  10.250000\n"
     ]
    }
   ],
   "source": [
    "print(weather_data_dates.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2451284-57f1-4638-886a-73de3e6256f6",
   "metadata": {},
   "source": [
    "## 3. Extension: Some Dataframe Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f28d8-74d3-49c8-a862-13ee57459755",
   "metadata": {},
   "source": [
    "1. Find the first three rows of data in `data/americas_gdp.csv` using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62eaf73a-acdc-4eb0-89d1-ef1fffd0640c",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.543238Z",
     "iopub.status.busy": "2023-10-23T10:34:48.542924Z",
     "iopub.status.idle": "2023-10-23T10:34:48.562506Z",
     "shell.execute_reply": "2023-10-23T10:34:48.560901Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>gdpPercap_1952</th>\n",
       "      <th>gdpPercap_1957</th>\n",
       "      <th>gdpPercap_1962</th>\n",
       "      <th>gdpPercap_1967</th>\n",
       "      <th>gdpPercap_1972</th>\n",
       "      <th>gdpPercap_1977</th>\n",
       "      <th>gdpPercap_1982</th>\n",
       "      <th>gdpPercap_1987</th>\n",
       "      <th>gdpPercap_1992</th>\n",
       "      <th>gdpPercap_1997</th>\n",
       "      <th>gdpPercap_2002</th>\n",
       "      <th>gdpPercap_2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Americas</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>5911.315053</td>\n",
       "      <td>6856.856212</td>\n",
       "      <td>7133.166023</td>\n",
       "      <td>8052.953021</td>\n",
       "      <td>9443.038526</td>\n",
       "      <td>10079.026740</td>\n",
       "      <td>8997.897412</td>\n",
       "      <td>9139.671389</td>\n",
       "      <td>9308.418710</td>\n",
       "      <td>10967.281950</td>\n",
       "      <td>8797.640716</td>\n",
       "      <td>12779.379640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Americas</td>\n",
       "      <td>Bolivia</td>\n",
       "      <td>2677.326347</td>\n",
       "      <td>2127.686326</td>\n",
       "      <td>2180.972546</td>\n",
       "      <td>2586.886053</td>\n",
       "      <td>2980.331339</td>\n",
       "      <td>3548.097832</td>\n",
       "      <td>3156.510452</td>\n",
       "      <td>2753.691490</td>\n",
       "      <td>2961.699694</td>\n",
       "      <td>3326.143191</td>\n",
       "      <td>3413.262690</td>\n",
       "      <td>3822.137084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Americas</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2108.944355</td>\n",
       "      <td>2487.365989</td>\n",
       "      <td>3336.585802</td>\n",
       "      <td>3429.864357</td>\n",
       "      <td>4985.711467</td>\n",
       "      <td>6660.118654</td>\n",
       "      <td>7030.835878</td>\n",
       "      <td>7807.095818</td>\n",
       "      <td>6950.283021</td>\n",
       "      <td>7957.980824</td>\n",
       "      <td>8131.212843</td>\n",
       "      <td>9065.800825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  continent    country  gdpPercap_1952  gdpPercap_1957  gdpPercap_1962  \\\n",
       "0  Americas  Argentina     5911.315053     6856.856212     7133.166023   \n",
       "1  Americas    Bolivia     2677.326347     2127.686326     2180.972546   \n",
       "2  Americas     Brazil     2108.944355     2487.365989     3336.585802   \n",
       "\n",
       "   gdpPercap_1967  gdpPercap_1972  gdpPercap_1977  gdpPercap_1982  \\\n",
       "0     8052.953021     9443.038526    10079.026740     8997.897412   \n",
       "1     2586.886053     2980.331339     3548.097832     3156.510452   \n",
       "2     3429.864357     4985.711467     6660.118654     7030.835878   \n",
       "\n",
       "   gdpPercap_1987  gdpPercap_1992  gdpPercap_1997  gdpPercap_2002  \\\n",
       "0     9139.671389     9308.418710    10967.281950     8797.640716   \n",
       "1     2753.691490     2961.699694     3326.143191     3413.262690   \n",
       "2     7807.095818     6950.283021     7957.980824     8131.212843   \n",
       "\n",
       "   gdpPercap_2007  \n",
       "0    12779.379640  \n",
       "1     3822.137084  \n",
       "2     9065.800825  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_americas = pd.read_csv('../data/americas_gdp.csv')\n",
    "data_americas.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff88d3-f459-4139-abc0-3d87a3a9fbd2",
   "metadata": {},
   "source": [
    "2. Find the last 3 **columns** of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c90192-74f7-4064-993b-f650108f81ea",
   "metadata": {},
   "source": [
    "_Hint: You may need to change your view of the data then you can use `tail()`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeeed721-06b5-4bf9-8f7b-326c52e8d23a",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.568401Z",
     "iopub.status.busy": "2023-10-23T10:34:48.567722Z",
     "iopub.status.idle": "2023-10-23T10:34:48.590173Z",
     "shell.execute_reply": "2023-10-23T10:34:48.589561Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gdpPercap_1997</th>\n",
       "      <td>10967.28195</td>\n",
       "      <td>3326.143191</td>\n",
       "      <td>7957.980824</td>\n",
       "      <td>28954.92589</td>\n",
       "      <td>10118.05318</td>\n",
       "      <td>6117.361746</td>\n",
       "      <td>6677.045314</td>\n",
       "      <td>5431.990415</td>\n",
       "      <td>3614.101285</td>\n",
       "      <td>7429.455877</td>\n",
       "      <td>...</td>\n",
       "      <td>9767.29753</td>\n",
       "      <td>2253.023004</td>\n",
       "      <td>7113.692252</td>\n",
       "      <td>4247.400261</td>\n",
       "      <td>5838.347657</td>\n",
       "      <td>16999.4333</td>\n",
       "      <td>8792.573126</td>\n",
       "      <td>35767.43303</td>\n",
       "      <td>9230.240708</td>\n",
       "      <td>10165.49518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gdpPercap_2002</th>\n",
       "      <td>8797.640716</td>\n",
       "      <td>3413.26269</td>\n",
       "      <td>8131.212843</td>\n",
       "      <td>33328.96507</td>\n",
       "      <td>10778.78385</td>\n",
       "      <td>5755.259962</td>\n",
       "      <td>7723.447195</td>\n",
       "      <td>6340.646683</td>\n",
       "      <td>4563.808154</td>\n",
       "      <td>5773.044512</td>\n",
       "      <td>...</td>\n",
       "      <td>10742.44053</td>\n",
       "      <td>2474.548819</td>\n",
       "      <td>7356.031934</td>\n",
       "      <td>3783.674243</td>\n",
       "      <td>5909.020073</td>\n",
       "      <td>18855.60618</td>\n",
       "      <td>11460.60023</td>\n",
       "      <td>39097.09955</td>\n",
       "      <td>7727.002004</td>\n",
       "      <td>8605.047831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gdpPercap_2007</th>\n",
       "      <td>12779.37964</td>\n",
       "      <td>3822.137084</td>\n",
       "      <td>9065.800825</td>\n",
       "      <td>36319.23501</td>\n",
       "      <td>13171.63885</td>\n",
       "      <td>7006.580419</td>\n",
       "      <td>9645.06142</td>\n",
       "      <td>8948.102923</td>\n",
       "      <td>6025.374752</td>\n",
       "      <td>6873.262326</td>\n",
       "      <td>...</td>\n",
       "      <td>11977.57496</td>\n",
       "      <td>2749.320965</td>\n",
       "      <td>9809.185636</td>\n",
       "      <td>4172.838464</td>\n",
       "      <td>7408.905561</td>\n",
       "      <td>19328.70901</td>\n",
       "      <td>18008.50924</td>\n",
       "      <td>42951.65309</td>\n",
       "      <td>10611.46299</td>\n",
       "      <td>11415.80569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0            1            2            3   \\\n",
       "gdpPercap_1997  10967.28195  3326.143191  7957.980824  28954.92589   \n",
       "gdpPercap_2002  8797.640716   3413.26269  8131.212843  33328.96507   \n",
       "gdpPercap_2007  12779.37964  3822.137084  9065.800825  36319.23501   \n",
       "\n",
       "                         4            5            6            7   \\\n",
       "gdpPercap_1997  10118.05318  6117.361746  6677.045314  5431.990415   \n",
       "gdpPercap_2002  10778.78385  5755.259962  7723.447195  6340.646683   \n",
       "gdpPercap_2007  13171.63885  7006.580419   9645.06142  8948.102923   \n",
       "\n",
       "                         8            9   ...           15           16  \\\n",
       "gdpPercap_1997  3614.101285  7429.455877  ...   9767.29753  2253.023004   \n",
       "gdpPercap_2002  4563.808154  5773.044512  ...  10742.44053  2474.548819   \n",
       "gdpPercap_2007  6025.374752  6873.262326  ...  11977.57496  2749.320965   \n",
       "\n",
       "                         17           18           19           20  \\\n",
       "gdpPercap_1997  7113.692252  4247.400261  5838.347657   16999.4333   \n",
       "gdpPercap_2002  7356.031934  3783.674243  5909.020073  18855.60618   \n",
       "gdpPercap_2007  9809.185636  4172.838464  7408.905561  19328.70901   \n",
       "\n",
       "                         21           22           23           24  \n",
       "gdpPercap_1997  8792.573126  35767.43303  9230.240708  10165.49518  \n",
       "gdpPercap_2002  11460.60023  39097.09955  7727.002004  8605.047831  \n",
       "gdpPercap_2007  18008.50924  42951.65309  10611.46299  11415.80569  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_americas.T.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191ea41-a5c3-491b-95f4-3834376d692d",
   "metadata": {},
   "source": [
    "3. Use `help(data_americas.to_csv)` to figure out how writing to a CSV file works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845a8b2a-99fb-4a84-bc5d-9570ceab556e",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.596909Z",
     "iopub.status.busy": "2023-10-23T10:34:48.596475Z",
     "iopub.status.idle": "2023-10-23T10:34:48.602236Z",
     "shell.execute_reply": "2023-10-23T10:34:48.601626Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', line_terminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string. If a non-binary file object is passed, it should\n",
      "        be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "        file object is passed, `mode` might need to contain a `'b'`.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "           Support for binary file objects was introduced.\n",
      "    \n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, default None\n",
      "        Format string for floating point numbers.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : str\n",
      "        Python write mode, default 'w'.\n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "        is a non-binary file object.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and '%s'\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). Set to\n",
      "        ``None`` for no compression. Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
      "        key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
      "        example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           May now be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Compression is supported for binary file objects.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Previous versions forwarded dict entries for 'gzip' to\n",
      "            `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      "            setting `mtime`.\n",
      "    \n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    line_terminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      "        starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      "        ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "    \n",
      "    To write a csv file to a new folder or nested folder you will first\n",
      "    need to create it using either Pathlib or os:\n",
      "    \n",
      "    >>> from pathlib import Path  # doctest: +SKIP\n",
      "    >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "    >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "    \n",
      "    >>> import os  # doctest: +SKIP\n",
      "    >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_americas.to_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e4bb5-39d5-4b8a-a366-b5a1a75ac3ad",
   "metadata": {},
   "source": [
    "4. Try writing to a CSV file using the code below (giving your own filename). Take a look in the data folder and check it's there.\n",
    "```\n",
    "data_americas.to_csv('data/new_file_name.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484efc19-edc1-4019-82d0-05a86db786a6",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-10-23T10:34:48.606432Z",
     "iopub.status.busy": "2023-10-23T10:34:48.605806Z",
     "iopub.status.idle": "2023-10-23T10:34:48.617979Z",
     "shell.execute_reply": "2023-10-23T10:34:48.616590Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "clear_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data_americas.to_csv('../data/processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
